# -*- coding: utf-8 -*-
"""Credit Scoring Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dlaO7EjxDkyxgn1kA49R7ZyRUkK7-kex
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import warnings
warnings.filterwarnings("ignore")

# STEP 1: Create a simulated dataset
np.random.seed(42)
num_samples = 5000

data = pd.DataFrame({
    'income': np.random.randint(20000, 120000, num_samples),
    'debt': np.random.randint(1000, 50000, num_samples),
    'on_time_payments': np.random.randint(10, 100, num_samples),
    'late_payments': np.random.randint(0, 20, num_samples),
    'credit_utilization': np.random.uniform(0.1, 1.0, num_samples),
    'loan_amount': np.random.randint(1000, 50000, num_samples),
    'loan_purpose': np.random.choice(['education', 'auto', 'home', 'personal'], num_samples),
    'credit_score': np.random.randint(300, 850, num_samples),
})
print(data)

# Target variable: 1 = Not Creditworthy, 0 = Creditworthy
data['defaulted'] = np.where((data['credit_score'] < 600) |
                             (data['late_payments'] > 5) |
                             (data['credit_utilization'] > 0.6), 1, 0)

# STEP 2: Feature Engineering
data['debt_to_income'] = data['debt'] / data['income']
data['payment_ratio'] = data['on_time_payments'] / (data['on_time_payments'] + data['late_payments'])

# Encode categorical features
le = LabelEncoder()
data['loan_purpose_encoded'] = le.fit_transform(data['loan_purpose'])

# Select features
features = [
    'income', 'debt', 'credit_utilization', 'loan_amount', 'credit_score',
    'debt_to_income', 'payment_ratio', 'loan_purpose_encoded'
]
X = data[features]
y = data['defaulted']

# Standardize features (important for Logistic Regression)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


# STEP 3: Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)



# STEP 4: Define models
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}

# STEP 5: Train and Evaluate
for name, model in models.items():
    print(f"\n===== {name} =====")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    print("ROC-AUC Score:", round(roc_auc_score(y_test, y_proba), 4))

# Optional: Show top 5 records
print("\nSample Data:\n")
print(data)